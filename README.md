# YOLO Deployment with NVIDIA Triton Inference Server (NIM)

**Complete Deployment Guide for YOLOv8/YOLOv11 on Oracle Cloud Infrastructure**

Production-ready solution for deploying YOLO object detection models using **NVIDIA Triton Inference Server** with **NIM (NVIDIA Inference Microservices)** optimization on Oracle Kubernetes Engine (OKE).

[![Platform](https://img.shields.io/badge/Platform-Oracle_Cloud-red)](https://cloud.oracle.com/)
[![GPU](https://img.shields.io/badge/GPU-NVIDIA_A10-green)](https://www.nvidia.com/en-us/data-center/products/a10-gpu/)
[![Triton](https://img.shields.io/badge/Inference-NVIDIA_Triton_Server-76B900)](https://developer.nvidia.com/triton-inference-server)

---

## ğŸš€ Why This Solution?

This repository demonstrates **production-grade YOLO deployment** with:


 **NVIDIA Triton Inference Server** - Industry-standard model serving

 **TensorRT Optimization** - 19.1x average speedup vs PyTorch

 **Multi-Model Support** - YOLOv8 (s/m/l/x) + YOLOv11 (s/m/l)

 **Protocol Flexibility** - HTTP and gRPC support

 **Dynamic Batching** - Automatic request batching for throughput

 **Comprehensive Benchmarking** - 28,000+ inferences tested

 **90% Cost Reduction** - Proven GPU infrastructure savings


**Platform:** Oracle Cloud Infrastructure (OCI) with NVIDIA A10 GPU
**Performance:** Up to **53.8x speedup**, **242 FPS** peak throughput, **28ms** lowest latency

---

## ğŸ¯ What's Included

This repository provides everything needed for production YOLO deployment:

### ğŸ³ Docker Images
- **PyTorch Baseline** - Standard Ultralytics YOLO (performance comparison)
- **TensorRT NIMs** - Optimized inference with NVIDIA Triton Server
  - nim-binary (HTTP), nim-grpc (gRPC), nim-batching (dynamic batching)

###  Kubernetes Deployments
- Production-ready manifests for all 4 configurations
- Service definitions, ConfigMaps, resource limits
- GPU scheduling and allocation

###  Benchmarking Suite
- Multi-model concurrent load testing
- Automated performance comparison
- Visual reporting and analysis

###  Proven Results
- Comprehensive benchmarking across 7 YOLO models
- 4 concurrency levels tested (C=1, 4, 16, 32)
- Real production data from OCI A10 GPU

##  Deployment Configurations

| Deployment | Framework | Protocols | GPU | Features | Best For |
|------------|-----------|-----------|-----|----------|----------|
| **base-yolo** | PyTorch | HTTP | GPU 0 | Baseline Flask app | Performance comparison |
| **nim-binary** | TensorRT | HTTP | GPU 1 | Binary protocol | Simple HTTP-only deployments |
| **nim-grpc** | TensorRT | HTTP + gRPC | GPU 2 | Low latency | Real-time applications |
| **nim-batching** | TensorRT | HTTP + gRPC | GPU 3 | Dynamic batching | High throughput workloads |

---

## ğŸ“ˆ Performance Benchmarking Results

Comprehensive benchmarking of **7 YOLO models** across **4 deployments** with **multiple concurrency levels** on OCI A10 GPU using NVIDIA Triton Inference Server.

**[ Full Detailed Report](results/benchmarking/README.md)** | **Test Date:** 2026-01-02 | **Total Inferences:** 28,000+

###  Top Performance Metrics

| Metric | Value | Configuration |
|--------|-------|---------------|
| ğŸš€ **Peak Throughput** | **242 FPS** | nim-grpc + yolov11l @ C=16 |
| âš¡ **Lowest Latency** | **28 ms** | nim-grpc + yolov8m @ C=32 |
| ğŸ“Š **Average TensorRT Speedup** | **19.1x** | vs PyTorch baseline |
| ğŸ¯ **Best Single Speedup** | **53.8x** | nim-grpc + yolov8m @ C=32 |
| ğŸ’° **GPU Cost Reduction** | **90%+** | Infrastructure savings |

### ğŸ“¸ Benchmarking Visualizations

#### Executive Performance Summary

Our comprehensive benchmarking across 7 YOLO models shows exceptional TensorRT performance gains:

![Executive Summary](results/benchmarking/images/executive/01_Executive_Summary.png)

*Figure 1: Executive summary dashboard showing key performance findings, speedup factors, and deployment comparisons*

---

#### Latency Performance Comparison

TensorRT deployments achieve consistent **10-15x lower latency** compared to PyTorch baseline:

![Latency Comparison](results/benchmarking/images/executive/02_Latency_Comparison.png)

*Figure 2: Mean and P95 latency comparison across all models. TensorRT maintains 28-118ms latency vs PyTorch's 1500ms at high concurrency*

---

#### Throughput Performance Comparison

All TensorRT deployments deliver **200+ FPS** while PyTorch bottlenecks at **21 FPS**:

![Throughput Comparison](results/benchmarking/images/executive/03_Throughput_Comparison.png)

*Figure 3: Frames per second (FPS) comparison showing TensorRT's 10-11x throughput advantage*

---

#### TensorRT Speedup Heatmap

Visual representation of **massive performance gains** across all model configurations:

![Speedup Heatmap](results/benchmarking/images/executive/04_Speedup_Heatmap.png)

*Figure 4: Color-coded speedup matrix. Green = exceptional performance (13-54x faster). TensorRT consistently outperforms PyTorch across all models*

---

#### Concurrency Scaling Analysis

Performance across different concurrency levels (C=1, 4, 16, 32):

**Optimal Concurrency Level: C=16** â­

![Concurrency 16 - Latency](results/benchmarking/images/per_concurrency/concurrency_16_latency.png)

*Figure 5: Latency at C=16 (optimal production setting). TensorRT: 57-63ms vs PyTorch: 745ms*

![Concurrency 16 - Throughput](results/benchmarking/images/per_concurrency/concurrency_16_throughput.png)

*Figure 6: Throughput at C=16. TensorRT NIMs achieve 225-243 FPS vs PyTorch's 21 FPS*

---

**High Concurrency Stress Test: C=32**

![Concurrency 32 - Latency](results/benchmarking/images/per_concurrency/concurrency_32_latency.png)

*Figure 7: Latency at C=32 (stress test). TensorRT maintains 28-112ms while PyTorch degrades to 1500ms*

---

### ğŸ“Š Performance Summary by Concurrency Level

#### Optimal Production Configuration (C=16) - RECOMMENDED â­

| Deployment | Latency | Throughput | Speedup | Reliability |
|------------|---------|------------|---------|-------------|
| base-yolo (PyTorch) | 746 ms | 21 FPS | Baseline | 100% |
| **nim-binary** | **58 ms** | **238 FPS** | **11.3x** | âœ… 100% |
| **nim-grpc** | **58 ms** | **242 FPS** | **11.5x** | âœ… 100% |
| **nim-batching** | **61 ms** | **233 FPS** | **11.1x** | âœ… 100% |

**Why C=16?** Perfect balance of throughput and latency. All deployments stable with 100% reliability.

#### High Concurrency Stress Test (C=32)

| Deployment | Latency | Throughput | Speedup | Reliability |
|------------|---------|------------|---------|-------------|
| base-yolo | 1500 ms | 21 FPS | Baseline | 100% |
| nim-binary | 112 ms | 224 FPS | 10.7x | âœ… 100% |
| **nim-grpc** | **28 ms** | **234 FPS** | **11.1x** | âœ… 100% |
| nim-batching | 101 ms | N/A | N/A | âš ï¸ 65% (errors) |

**âš ï¸ Important:** nim-batching experiences GPU memory pressure at C=32. Use Câ‰¤16 for production stability.

---

### ğŸ¯ Production Deployment Recommendations

Based on 28,000+ benchmark inferences, here are proven configurations:

#### For Real-Time Applications (Lowest Latency Priority)
```yaml
Deployment: nim-grpc
Model: yolov8m or yolov11m
Concurrency: 16-32
Expected Performance:
  - Latency: 28-61 ms (mean)
  - Throughput: 234-243 FPS
  - Reliability: 100%
  - Use Case: Live video analytics, interactive AI
```

#### For Batch Processing (Highest Throughput Priority)
```yaml
Deployment: nim-grpc or nim-binary
Model: yolov11l
Concurrency: 16
Expected Performance:
  - Latency: 58 ms (mean)
  - Throughput: 242 FPS (peak)
  - Reliability: 100%
  - Use Case: Video file processing, large-scale annotation
```

#### For Cost Optimization (Balanced Performance)
```yaml
Deployment: nim-binary (simpler HTTP)
Model: yolov8m
Concurrency: 16
Expected Performance:
  - Latency: 57 ms
  - Throughput: 243 FPS
  - Cost Savings: 90% GPU reduction
  - Use Case: General production workloads, SaaS platforms
```

### ğŸ’° Cost-Performance Analysis

**Example: Achieving 1000 FPS Target**

| Deployment | GPUs Required | Monthly Cost* | Annual Cost | Savings |
|------------|---------------|---------------|-------------|---------|
| PyTorch Baseline | ~48 GPUs | $57,600 | $691,200 | Baseline |
| **TensorRT (nim-grpc)** | **4 GPUs** | **$4,800** | **$57,600** | **$633,600/year** |

*Based on OCI GPU.A10 pricing at $1,200/GPU/month

**ROI:** TensorRT NIMs deliver **10-20x higher throughput per GPU**, enabling **85-95% reduction** in infrastructure costs.

---

## ğŸš€ Quick Start - Deployment Guide

### Prerequisites
- OCI CLI configured
- kubectl configured for OKE cluster
- Docker installed
- Access to OCIR (Oracle Container Infrastructure Registry)

### 1. Build and Push Images

```bash
# Build base-yolo (PyTorch baseline)
cd docker/base-yolo
docker build -t fra.ocir.io/<namespace>/yolo-base-pytorch:latest .
docker push fra.ocir.io/<namespace>/yolo-base-pytorch:latest

# Build NIM images (TensorRT)
cd ../nim-binary
docker build -t fra.ocir.io/<namespace>/yolo-nim-binary:latest .
docker push fra.ocir.io/<namespace>/yolo-nim-binary:latest

# Repeat for nim-grpc and nim-batching
```

### 2. Deploy to Kubernetes

```bash
# Deploy all 4 configurations
kubectl apply -f kubernetes/base-yolo/
kubectl apply -f kubernetes/nim-binary/
kubectl apply -f kubernetes/nim-grpc/
kubectl apply -f kubernetes/nim-batching/

# Check deployments
kubectl get pods -A | grep yolo
```

### 3. Run Benchmarks

```bash
cd benchmarking

# Terminal 1: Setup port forwarding
./setup_port_forwarding.sh

# Terminal 2: Run benchmarks
python3 benchmark_all_pods.py
```

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ docker/                      # Docker images
â”‚   â”œâ”€â”€ base-yolo/              # PyTorch baseline
â”‚   â”œâ”€â”€ nim-binary/             # TensorRT HTTP binary
â”‚   â”œâ”€â”€ nim-grpc/               # TensorRT gRPC
â”‚   â””â”€â”€ nim-batching/           # TensorRT with dynamic batching
â”‚
â”œâ”€â”€ kubernetes/                  # Kubernetes manifests
â”‚   â”œâ”€â”€ base-yolo/              # Deployment, Service, ConfigMap
â”‚   â”œâ”€â”€ nim-binary/             # Deployment, Service
â”‚   â”œâ”€â”€ nim-grpc/               # Deployment, Service
â”‚   â””â”€â”€ nim-batching/           # Deployment, Service
â”‚
â”œâ”€â”€ benchmarking/               # Benchmarking suite
â”‚   â”œâ”€â”€ benchmark_all_pods.py  # Main orchestrator
â”‚   â”œâ”€â”€ benchmark_internal_universal.py  # NIM benchmark
â”‚   â”œâ”€â”€ benchmark_base_yolo*.py # PyTorch benchmarks
â”‚   â”œâ”€â”€ setup_port_forwarding.sh
â”‚   â””â”€â”€ docs/                   # Guides and documentation
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ build-all.sh           # Build all images
â”‚   â”œâ”€â”€ push-all.sh            # Push all to OCIR
â”‚   â””â”€â”€ deploy-all.sh          # Deploy all to K8s
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”‚   â”œâ”€â”€ BENCHMARKING_GUIDE.md
â”‚   â””â”€â”€ TROUBLESHOOTING.md
â”‚
â””â”€â”€ results/                    # Benchmark results and analysis
    â”œâ”€â”€ benchmarking/           # Comprehensive benchmarking report
    â”‚   â”œâ”€â”€ README.md           # Full analysis and recommendations
    â”‚   â”œâ”€â”€ aggregated_results.csv  # Raw benchmark data
    â”‚   â””â”€â”€ images/             # Performance charts
    â”‚       â”œâ”€â”€ executive/      # Executive summary dashboards
    â”‚       â”œâ”€â”€ per_concurrency/  # C=1,4,16,32 analysis
    â”‚       â””â”€â”€ per_model/      # Per-model scaling charts
    â”œâ”€â”€ sequential/             # Legacy sequential test results
    â””â”€â”€ concurrent/             # Legacy concurrent test results
```

## ğŸ”§ Configuration

### OCIR Settings

Update image references in Kubernetes manifests:
```yaml
image: fra.ocir.io/<your-namespace>/yolo-base-pytorch:latest
```

### Concurrency Settings

Edit `benchmarking/benchmark_all_pods.py`:
```python
ITERATIONS = 50          # Number of requests
CONCURRENCY = 1          # 1=sequential, 8+=concurrent load testing
```

## ğŸ“ Key Learnings from Benchmarking

### Performance Insights

1. **TensorRT Delivers Massive Speedup**
   - Average 19.1x speedup vs PyTorch baseline
   - Up to 53.8x for specific model configurations
   - Consistent performance across all 7 YOLO models tested

2. **Concurrency Level Matters**
   - C=16 is the optimal sweet spot for TensorRT deployments
   - PyTorch bottlenecks at C=4+ (GIL limitation)
   - nim-batching requires Câ‰¤16 for stability

3. **Protocol Choice Impact**
   - nim-grpc: Best latency (28ms minimum @ C=32)
   - nim-binary: Best reliability and simple integration
   - nim-batching: Best for C=8-16, avoid C=32

4. **Infrastructure Cost Savings**
   - 90%+ reduction in GPU infrastructure costs
   - 11.7x lower cost per inference
   - Faster processing enables better user experience

5. **Model Selection Trade-offs**
   - Medium models (yolov8m/yolov11m): Best balance
   - Small models (yolov8s/yolov11s): Highest FPS
   - Large models (yolov8l/yolov11l/yolov8x): Best accuracy

### Production Deployment Insights

- **NVIDIA Triton Server with NIM** provides production-grade inference with TensorRT optimization
- **FP16 precision** and **CUDA Graphs** enable maximum GPU utilization
- **Dynamic batching** (nim-batching) requires careful concurrency tuning
- **gRPC protocol** outperforms HTTP for low-latency scenarios
- **Concurrency planning** is critical - test your specific workload patterns

## ğŸ“š Documentation

- **[Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Detailed deployment instructions
- **[Benchmarking Guide](docs/BENCHMARKING_GUIDE.md)** - Complete benchmarking documentation
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions

## ğŸ› ï¸ Troubleshooting

### Images Not Pulling
```bash
# Create image pull secret
kubectl create secret docker-registry ocir-secret \
  --docker-server=fra.ocir.io \
  --docker-username='<tenancy>/<username>' \
  --docker-password='<auth-token>'
```

### Pod Not Starting
```bash
# Check logs
kubectl logs -n <namespace> <pod-name>

# Check events
kubectl describe pod -n <namespace> <pod-name>
```

### Benchmark Failing
```bash
# Verify port forwarding
curl http://127.0.0.1:8000/v2/health/ready

# Check concurrency level (reduce if too high)
CONCURRENCY = 8  # Start with 8, not 32+
```

## ğŸ“„ License

Internal Oracle CoE project.

## ğŸ¤ Contributing

This is an Oracle AI CoE project. For questions or contributions, contact the AI CoE team.

## ğŸ“§ Support

For issues or questions:
1. Check [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
2. Review benchmark logs in `results/`
3. Contact Oracle AI CoE team

---

## ğŸ—ï¸ Architecture Overview

This solution uses **NVIDIA Triton Inference Server** with **NIM (NVIDIA Inference Microservices)** for production-grade YOLO deployment:

- **PyTorch Baseline (base-yolo):** Standard Ultralytics YOLO inference
- **TensorRT NIMs (nim-binary/grpc/batching):** Optimized inference with:
  - TensorRT engine conversion (FP16 precision)
  - CUDA Graphs for minimal kernel launch overhead
  - Dynamic batching for high-concurrency workloads (nim-batching)
  - Multi-protocol support (HTTP and gRPC)

**Why Triton + NIM?**
- Production-ready inference serving platform
- Standardized model deployment
- Built-in observability and monitoring
- Efficient GPU resource utilization
- Protocol flexibility (HTTP/gRPC)

---

**Last Updated:** 2026-01-02
**Version:** 2.0.0 (with comprehensive benchmarking results)
**Author:** Oracle AI CoE Team
**Platform:** Oracle Cloud Infrastructure with NVIDIA A10 GPU
**Inference Server:** NVIDIA Triton Inference Server with NIM
